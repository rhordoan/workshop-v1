{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module E: LoRA/QLoRA Fine-tuning Lab (Text-to-SQL)\n",
        "\n",
        "**Goal:** Fine-tune a small instruction model to translate natural-language credit/risk questions into **SQLite SQL** using **QLoRA** (4-bit base + LoRA adapters).\n",
        "\n",
        "**Persona:** FICO Cloud Engineer (cost/latency/privacy + deployment mindset)\n",
        "\n",
        "## What you'll build\n",
        "- A synthetic, FICO-flavored SQLite database (`customers`, `accounts`, `transactions`, `credit_applications`)\n",
        "- A labeled Text-to-SQL dataset that is **validated by execution**\n",
        "- A baseline model evaluation (exact match + execution match)\n",
        "- A short but real **QLoRA training run** that saves adapter weights\n",
        "- A post-tune evaluation + deployment-minded adapter loading (optional merge)\n",
        "\n",
        "---\n",
        "\n",
        "## Why parameter-efficient fine-tuning (PEFT)?\n",
        "Full fine-tuning updates *all* model weights — expensive and operationally heavy.\n",
        "\n",
        "**LoRA** updates only small low-rank matrices injected into key linear layers.\n",
        "\n",
        "**QLoRA** combines:\n",
        "- **4-bit** quantized *frozen* base model weights (cheap to store + load)\n",
        "- **LoRA adapters** (small, trainable, easy to version and ship)\n",
        "\n",
        "This is a practical deployment pattern:\n",
        "- Host one base model once\n",
        "- Load per-tenant/per-task adapters on demand\n",
        "\n",
        "---\n",
        "\n",
        "## Sections\n",
        "- Part 0 — Setup + constraints\n",
        "- Part 1 — What \"modern fine-tuning\" means (PEFT only)\n",
        "- Part 2 — Synthetic Text-to-SQL dataset + sqlite ground truth\n",
        "- Part 3 — Baseline inference (before tuning)\n",
        "- Part 4 — QLoRA training (the main event)\n",
        "- Part 5 — Evaluation after tuning\n",
        "- Part 6 — Deployment mindset (adapter-only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 0 — Setup + Constraints\n",
        "\n",
        "We'll verify GPU availability, import libraries, and set a deterministic seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: /home/shadeform/workshop-v1/fico/.venv/bin/python\n",
            "Working dir: /home/shadeform/workshop-v1/fico\n",
            "✅ GPU: NVIDIA H200 (150.0 GB VRAM)\n",
            "\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Environment check: GPU / VRAM\n",
        "# ============================================================\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Python:\", sys.executable)\n",
        "print(\"Working dir:\", os.getcwd())\n",
        "\n",
        "# GPU check\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"✅ GPU: {gpu_name} ({vram_gb:.1f} GB VRAM)\")\n",
        "        DEVICE = \"cuda\"\n",
        "    else:\n",
        "        print(\"⚠️  No CUDA GPU detected — training will be slow (CPU mode)\")\n",
        "        DEVICE = \"cpu\"\n",
        "except ImportError:\n",
        "    print(\"❌ PyTorch not installed\")\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "print(f\"\\nUsing device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All imports successful\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Imports\n",
        "# ============================================================\n",
        "import random\n",
        "import sqlite3\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        "    PeftModel,\n",
        ")\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, Markdown, clear_output\n",
        "\n",
        "print(\"✅ All imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Random seed set to 42\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Reproducibility: set seeds\n",
        "# ============================================================\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"✅ Random seed set to {SEED}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1 — What \"Modern Fine-tuning\" Means (PEFT Only)\n",
        "\n",
        "We will **not** do full fine-tuning. Instead we use **LoRA / QLoRA**.\n",
        "\n",
        "## Key Idea\n",
        "```\n",
        "┌──────────────────────────────────────────────────────────────────┐\n",
        "│  Frozen 4-bit Base Weights   │  Trainable LoRA Adapters (r×d)   │\n",
        "│  ~1.5 B params (quantized)   │  ~1-5 M params (fp16/bf16)       │\n",
        "└──────────────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "**What gets trained?**\n",
        "- Two small matrices **A** (d × r) and **B** (r × d) per target linear layer\n",
        "- Effective weight update: `ΔW = B @ A` (low-rank)\n",
        "\n",
        "**What stays frozen?**\n",
        "- The original model weights (stored in 4-bit NF4)\n",
        "\n",
        "**Benefits:**\n",
        "| Aspect | Full Fine-tune | QLoRA |\n",
        "|--------|----------------|-------|\n",
        "| Trainable params | 100% | ~0.1-1% |\n",
        "| GPU VRAM | 24-80 GB | 6-16 GB |\n",
        "| Artifact size | Full model | Small adapter |\n",
        "| Multi-tenant | Hard | Easy (swap adapters) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example LoraConfig:\n",
            "LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, peft_version='0.18.0', base_model_name_or_path=None, revision=None, inference_mode=False, r=16, target_modules={'v_proj', 'q_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, alora_invocation_tokens=None, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, arrow_config=None, ensure_weight_tying=False)\n"
          ]
        }
      ],
      "source": [
        "# Quick demo: what does a LoRA config look like?\n",
        "demo_lora_config = LoraConfig(\n",
        "    r=16,                          # rank of the low-rank matrices\n",
        "    lora_alpha=32,                 # scaling factor (alpha / r)\n",
        "    lora_dropout=0.05,             # dropout on adapter activations\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],  # which layers to adapt\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "print(\"Example LoraConfig:\")\n",
        "print(demo_lora_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2 — Synthetic Text-to-SQL Dataset + SQLite Ground Truth\n",
        "\n",
        "We'll create a small FICO-flavored schema in **SQLite (in-memory)**, populate it with synthetic data, then generate a labeled dataset of (NL question, gold SQL) pairs.\n",
        "\n",
        "## Schema\n",
        "- `customers` — customer_id, name, email, fico_score, created_at\n",
        "- `accounts` — account_id, customer_id, account_type, balance, opened_at\n",
        "- `transactions` — txn_id, account_id, amount, txn_type, txn_date\n",
        "- `credit_applications` — app_id, customer_id, requested_amount, status, decision_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Schema created\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Create the SQLite database + schema\n",
        "# ============================================================\n",
        "\n",
        "DB_PATH = \":memory:\"  # in-memory; change to file path if you want persistence\n",
        "\n",
        "def get_connection():\n",
        "    \"\"\"Return a fresh connection to the database.\"\"\"\n",
        "    return sqlite3.connect(DB_PATH, check_same_thread=False)\n",
        "\n",
        "def init_schema(conn: sqlite3.Connection):\n",
        "    \"\"\"Create tables.\"\"\"\n",
        "    cur = conn.cursor()\n",
        "    cur.executescript(\"\"\"\n",
        "        DROP TABLE IF EXISTS customers;\n",
        "        DROP TABLE IF EXISTS accounts;\n",
        "        DROP TABLE IF EXISTS transactions;\n",
        "        DROP TABLE IF EXISTS credit_applications;\n",
        "\n",
        "        CREATE TABLE customers (\n",
        "            customer_id INTEGER PRIMARY KEY,\n",
        "            name TEXT NOT NULL,\n",
        "            email TEXT,\n",
        "            fico_score INTEGER,\n",
        "            created_at TEXT\n",
        "        );\n",
        "\n",
        "        CREATE TABLE accounts (\n",
        "            account_id INTEGER PRIMARY KEY,\n",
        "            customer_id INTEGER,\n",
        "            account_type TEXT,   -- 'checking', 'savings', 'credit'\n",
        "            balance REAL,\n",
        "            opened_at TEXT,\n",
        "            FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "        );\n",
        "\n",
        "        CREATE TABLE transactions (\n",
        "            txn_id INTEGER PRIMARY KEY,\n",
        "            account_id INTEGER,\n",
        "            amount REAL,\n",
        "            txn_type TEXT,       -- 'credit', 'debit'\n",
        "            txn_date TEXT,\n",
        "            FOREIGN KEY (account_id) REFERENCES accounts(account_id)\n",
        "        );\n",
        "\n",
        "        CREATE TABLE credit_applications (\n",
        "            app_id INTEGER PRIMARY KEY,\n",
        "            customer_id INTEGER,\n",
        "            requested_amount REAL,\n",
        "            status TEXT,         -- 'approved', 'denied', 'pending'\n",
        "            decision_date TEXT,\n",
        "            FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
        "        );\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "# Initialize\n",
        "conn = get_connection()\n",
        "init_schema(conn)\n",
        "print(\"✅ Schema created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data populated: 50 customers, 97 accounts, 689 transactions, 38 applications\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Populate with synthetic data\n",
        "# ============================================================\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "FIRST_NAMES = [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Eva\", \"Frank\", \"Grace\", \"Henry\", \"Ivy\", \"Jack\"]\n",
        "LAST_NAMES = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Martinez\", \"Wilson\"]\n",
        "ACCOUNT_TYPES = [\"checking\", \"savings\", \"credit\"]\n",
        "TXN_TYPES = [\"credit\", \"debit\"]\n",
        "APP_STATUSES = [\"approved\", \"denied\", \"pending\"]\n",
        "\n",
        "def random_date(start_year=2020, end_year=2024):\n",
        "    start = datetime(start_year, 1, 1)\n",
        "    end = datetime(end_year, 12, 31)\n",
        "    delta = (end - start).days\n",
        "    return (start + timedelta(days=random.randint(0, delta))).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def populate_data(conn, n_customers=50):\n",
        "    cur = conn.cursor()\n",
        "    for cid in range(1, n_customers + 1):\n",
        "        name = f\"{random.choice(FIRST_NAMES)} {random.choice(LAST_NAMES)}\"\n",
        "        email = f\"user{cid}@example.com\"\n",
        "        fico = random.randint(300, 850)\n",
        "        created = random_date(2018, 2022)\n",
        "        cur.execute(\"INSERT INTO customers VALUES (?, ?, ?, ?, ?)\", (cid, name, email, fico, created))\n",
        "    \n",
        "    aid = 1\n",
        "    for cid in range(1, n_customers + 1):\n",
        "        for _ in range(random.randint(1, 3)):\n",
        "            atype = random.choice(ACCOUNT_TYPES)\n",
        "            balance = round(random.uniform(-5000, 50000), 2)\n",
        "            opened = random_date(2019, 2023)\n",
        "            cur.execute(\"INSERT INTO accounts VALUES (?, ?, ?, ?, ?)\", (aid, cid, atype, balance, opened))\n",
        "            aid += 1\n",
        "    \n",
        "    tid = 1\n",
        "    cur.execute(\"SELECT account_id FROM accounts\")\n",
        "    account_ids = [r[0] for r in cur.fetchall()]\n",
        "    for acc_id in random.sample(account_ids, min(len(account_ids), 60)):\n",
        "        for _ in range(random.randint(5, 20)):\n",
        "            amt = round(random.uniform(5, 2000), 2)\n",
        "            ttype = random.choice(TXN_TYPES)\n",
        "            tdate = random_date(2022, 2024)\n",
        "            cur.execute(\"INSERT INTO transactions VALUES (?, ?, ?, ?, ?)\", (tid, acc_id, amt, ttype, tdate))\n",
        "            tid += 1\n",
        "    \n",
        "    appid = 1\n",
        "    for cid in random.sample(range(1, n_customers + 1), n_customers // 2):\n",
        "        for _ in range(random.randint(1, 2)):\n",
        "            req_amt = round(random.uniform(1000, 50000), 2)\n",
        "            status = random.choice(APP_STATUSES)\n",
        "            dec_date = random_date(2023, 2024)\n",
        "            cur.execute(\"INSERT INTO credit_applications VALUES (?, ?, ?, ?, ?)\", (appid, cid, req_amt, status, dec_date))\n",
        "            appid += 1\n",
        "    conn.commit()\n",
        "    return aid - 1, tid - 1, appid - 1\n",
        "\n",
        "n_accounts, n_txns, n_apps = populate_data(conn, n_customers=50)\n",
        "print(f\"Data populated: 50 customers, {n_accounts} accounts, {n_txns} transactions, {n_apps} applications\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>name</th>\n",
              "      <th>email</th>\n",
              "      <th>fico_score</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Bob Smith</td>\n",
              "      <td>user1@example.com</td>\n",
              "      <td>581</td>\n",
              "      <td>2019-05-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>David Williams</td>\n",
              "      <td>user2@example.com</td>\n",
              "      <td>404</td>\n",
              "      <td>2021-10-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ivy Johnson</td>\n",
              "      <td>user3@example.com</td>\n",
              "      <td>732</td>\n",
              "      <td>2018-03-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Alice Johnson</td>\n",
              "      <td>user4@example.com</td>\n",
              "      <td>523</td>\n",
              "      <td>2019-04-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Ivy Wilson</td>\n",
              "      <td>user5@example.com</td>\n",
              "      <td>327</td>\n",
              "      <td>2021-02-23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_id            name              email  fico_score  created_at\n",
              "0            1       Bob Smith  user1@example.com         581  2019-05-17\n",
              "1            2  David Williams  user2@example.com         404  2021-10-17\n",
              "2            3     Ivy Johnson  user3@example.com         732  2018-03-07\n",
              "3            4   Alice Johnson  user4@example.com         523  2019-04-22\n",
              "4            5      Ivy Wilson  user5@example.com         327  2021-02-23"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Quick sanity check\n",
        "pd.read_sql(\"SELECT * FROM customers LIMIT 5\", conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset built: 17 examples\n",
            "  simple: 8\n",
            "  medium: 5\n",
            "  complex: 4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Generate a labeled Text-to-SQL dataset\n",
        "# ============================================================\n",
        "\n",
        "SCHEMA_CONTEXT = \"\"\"\n",
        "Tables:\n",
        "- customers(customer_id, name, email, fico_score, created_at)\n",
        "- accounts(account_id, customer_id, account_type, balance, opened_at)\n",
        "- transactions(txn_id, account_id, amount, txn_type, txn_date)\n",
        "- credit_applications(app_id, customer_id, requested_amount, status, decision_date)\n",
        "\"\"\"\n",
        "\n",
        "# Templates: (instruction, sql, difficulty)\n",
        "TEMPLATES = [\n",
        "    # Simple (single table, no join)\n",
        "    (\"How many customers are there?\", \"SELECT COUNT(*) FROM customers;\", \"simple\"),\n",
        "    (\"List all customer names.\", \"SELECT name FROM customers;\", \"simple\"),\n",
        "    (\"What is the average FICO score?\", \"SELECT AVG(fico_score) FROM customers;\", \"simple\"),\n",
        "    (\"Show customers with FICO score above 700.\", \"SELECT * FROM customers WHERE fico_score > 700;\", \"simple\"),\n",
        "    (\"How many accounts are of type 'checking'?\", \"SELECT COUNT(*) FROM accounts WHERE account_type = 'checking';\", \"simple\"),\n",
        "    (\"What is the total balance across all accounts?\", \"SELECT SUM(balance) FROM accounts;\", \"simple\"),\n",
        "    (\"List all transactions over 500 dollars.\", \"SELECT * FROM transactions WHERE amount > 500;\", \"simple\"),\n",
        "    (\"How many credit applications are pending?\", \"SELECT COUNT(*) FROM credit_applications WHERE status = 'pending';\", \"simple\"),\n",
        "    \n",
        "    # Medium (single join or GROUP BY)\n",
        "    (\"Show the total balance per customer.\", \n",
        "     \"SELECT c.customer_id, c.name, SUM(a.balance) AS total_balance FROM customers c JOIN accounts a ON c.customer_id = a.customer_id GROUP BY c.customer_id;\", \n",
        "     \"medium\"),\n",
        "    (\"How many accounts does each customer have?\", \n",
        "     \"SELECT c.customer_id, c.name, COUNT(a.account_id) AS num_accounts FROM customers c JOIN accounts a ON c.customer_id = a.customer_id GROUP BY c.customer_id;\", \n",
        "     \"medium\"),\n",
        "    (\"What is the average transaction amount per account?\", \n",
        "     \"SELECT account_id, AVG(amount) AS avg_amount FROM transactions GROUP BY account_id;\", \n",
        "     \"medium\"),\n",
        "    (\"List customers who have applied for credit.\", \n",
        "     \"SELECT DISTINCT c.customer_id, c.name FROM customers c JOIN credit_applications ca ON c.customer_id = ca.customer_id;\", \n",
        "     \"medium\"),\n",
        "    (\"Show all approved credit applications with customer names.\", \n",
        "     \"SELECT c.name, ca.requested_amount, ca.decision_date FROM customers c JOIN credit_applications ca ON c.customer_id = ca.customer_id WHERE ca.status = 'approved';\", \n",
        "     \"medium\"),\n",
        "    \n",
        "    # Complex (multi-join, subquery, or aggregation+filter)\n",
        "    (\"Find customers with FICO above 750 who have been denied credit.\", \n",
        "     \"SELECT c.customer_id, c.name, c.fico_score FROM customers c JOIN credit_applications ca ON c.customer_id = ca.customer_id WHERE c.fico_score > 750 AND ca.status = 'denied';\", \n",
        "     \"complex\"),\n",
        "    (\"What is the total transaction amount for customers with savings accounts?\", \n",
        "     \"SELECT SUM(t.amount) FROM transactions t JOIN accounts a ON t.account_id = a.account_id WHERE a.account_type = 'savings';\", \n",
        "     \"complex\"),\n",
        "    (\"Show the top 5 customers by total account balance.\", \n",
        "     \"SELECT c.customer_id, c.name, SUM(a.balance) AS total FROM customers c JOIN accounts a ON c.customer_id = a.customer_id GROUP BY c.customer_id ORDER BY total DESC LIMIT 5;\", \n",
        "     \"complex\"),\n",
        "    (\"List customers who have more than 2 accounts.\", \n",
        "     \"SELECT c.customer_id, c.name, COUNT(a.account_id) AS cnt FROM customers c JOIN accounts a ON c.customer_id = a.customer_id GROUP BY c.customer_id HAVING cnt > 2;\", \n",
        "     \"complex\"),\n",
        "]\n",
        "\n",
        "def validate_sql(conn, sql: str) -> Tuple[bool, Any]:\n",
        "    \"\"\"Execute SQL and return (success, result_or_error).\"\"\"\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(sql)\n",
        "        rows = cur.fetchall()\n",
        "        return True, rows\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "def build_dataset(conn, templates: List[Tuple[str, str, str]]) -> List[Dict]:\n",
        "    \"\"\"Build dataset from templates, validating each SQL.\"\"\"\n",
        "    dataset = []\n",
        "    for instruction, sql, difficulty in templates:\n",
        "        ok, result = validate_sql(conn, sql)\n",
        "        if not ok:\n",
        "            print(f\"WARNING: SQL failed validation: {sql[:50]}... -> {result}\")\n",
        "            continue\n",
        "        dataset.append({\n",
        "            \"instruction\": instruction,\n",
        "            \"context\": SCHEMA_CONTEXT.strip(),\n",
        "            \"response\": sql.strip(),\n",
        "            \"difficulty\": difficulty,\n",
        "            \"num_rows\": len(result) if isinstance(result, list) else 0,\n",
        "        })\n",
        "    return dataset\n",
        "\n",
        "text2sql_data = build_dataset(conn, TEMPLATES)\n",
        "print(f\"Dataset built: {len(text2sql_data)} examples\")\n",
        "print(f\"  simple: {sum(1 for d in text2sql_data if d['difficulty']=='simple')}\")\n",
        "print(f\"  medium: {sum(1 for d in text2sql_data if d['difficulty']=='medium')}\")\n",
        "print(f\"  complex: {sum(1 for d in text2sql_data if d['difficulty']=='complex')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative: Load Pre-Generated Dataset (Recommended)\n",
        "\n",
        "Instead of using the small template-based dataset above, load a larger LLM-generated dataset from `text2sql_generated.json`.\n",
        "\n",
        "This cell performs a **stratified train/test split** — ensuring each difficulty level is proportionally represented in both sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 221 examples from text2sql_generated.json\n",
            "\n",
            "Difficulty distribution:\n",
            "  complex: 60 (27.1%)\n",
            "  medium: 66 (29.9%)\n",
            "  simple: 95 (43.0%)\n",
            "\n",
            "✅ Stratified split complete:\n",
            "   Train: 198 examples\n",
            "   Eval:  23 examples\n",
            "\n",
            "   Train distribution:\n",
            "     complex: 54\n",
            "     medium: 59\n",
            "     simple: 85\n",
            "\n",
            "   Eval distribution:\n",
            "     complex: 6\n",
            "     medium: 7\n",
            "     simple: 10\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Load External Dataset + Stratified Train/Test Split\n",
        "# ============================================================\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "DATASET_PATH = Path(\"text2sql_generated.json\")\n",
        "TRAIN_RATIO = 0.9  # 90% train, 10% eval\n",
        "\n",
        "if DATASET_PATH.exists():\n",
        "    with open(DATASET_PATH) as f:\n",
        "        all_examples = json.load(f)\n",
        "    \n",
        "    print(f\"Loaded {len(all_examples)} examples from {DATASET_PATH}\")\n",
        "    \n",
        "    # Show difficulty distribution\n",
        "    difficulty_counts = Counter(ex[\"difficulty\"] for ex in all_examples)\n",
        "    print(\"\\nDifficulty distribution:\")\n",
        "    for diff, count in sorted(difficulty_counts.items()):\n",
        "        print(f\"  {diff}: {count} ({100*count/len(all_examples):.1f}%)\")\n",
        "    \n",
        "    # Stratified split by difficulty\n",
        "    difficulties = [ex[\"difficulty\"] for ex in all_examples]\n",
        "    \n",
        "    train_examples, eval_examples = train_test_split(\n",
        "        all_examples,\n",
        "        train_size=TRAIN_RATIO,\n",
        "        stratify=difficulties,\n",
        "        random_state=SEED\n",
        "    )\n",
        "    \n",
        "    # Convert to the format expected by the rest of the notebook\n",
        "    # Add schema context to each example\n",
        "    SCHEMA_CONTEXT = \"\"\"Tables:\n",
        "- customers (customer_id, name, email, fico_score, created_at)\n",
        "- accounts (account_id, customer_id, account_type, balance, opened_at)\n",
        "- transactions (txn_id, account_id, amount, txn_type, txn_date)\n",
        "- credit_applications (app_id, customer_id, requested_amount, status, decision_date)\"\"\"\n",
        "\n",
        "    def convert_example(ex):\n",
        "        return {\n",
        "            \"instruction\": ex[\"instruction\"],\n",
        "            \"context\": SCHEMA_CONTEXT,\n",
        "            \"response\": ex[\"sql\"],\n",
        "            \"difficulty\": ex[\"difficulty\"]\n",
        "        }\n",
        "    \n",
        "    text2sql_train = [convert_example(ex) for ex in train_examples]\n",
        "    text2sql_eval = [convert_example(ex) for ex in eval_examples]\n",
        "    \n",
        "    # Also update text2sql_data for backward compatibility with other cells\n",
        "    text2sql_data = text2sql_train + text2sql_eval\n",
        "    \n",
        "    # Show split statistics\n",
        "    print(f\"\\n✅ Stratified split complete:\")\n",
        "    print(f\"   Train: {len(text2sql_train)} examples\")\n",
        "    print(f\"   Eval:  {len(text2sql_eval)} examples\")\n",
        "    \n",
        "    # Verify stratification\n",
        "    train_diffs = Counter(ex[\"difficulty\"] for ex in text2sql_train)\n",
        "    eval_diffs = Counter(ex[\"difficulty\"] for ex in text2sql_eval)\n",
        "    \n",
        "    print(\"\\n   Train distribution:\")\n",
        "    for diff in sorted(train_diffs.keys()):\n",
        "        print(f\"     {diff}: {train_diffs[diff]}\")\n",
        "    \n",
        "    print(\"\\n   Eval distribution:\")\n",
        "    for diff in sorted(eval_diffs.keys()):\n",
        "        print(f\"     {diff}: {eval_diffs[diff]}\")\n",
        "        \n",
        "else:\n",
        "    print(f\"⚠️ Dataset file not found: {DATASET_PATH}\")\n",
        "    print(\"   Using the smaller template-based dataset from above.\")\n",
        "    print(\"   To use a larger dataset, generate one with the LLM prompt and save as text2sql_generated.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interactive: Explore the Dataset\n",
        "\n",
        "Pick an example to see its schema, NL question, gold SQL, and a preview of the executed result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "308f55ae7e0543a69c21e92b13bf6310",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "IntSlider(value=0, description='Example #', max=220)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60c2e2b466754c809214574f7968912e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Interactive widget to explore dataset\n",
        "w_example_idx = widgets.IntSlider(value=0, min=0, max=len(text2sql_data)-1, description=\"Example #\")\n",
        "w_output = widgets.Output()\n",
        "\n",
        "def show_example(idx):\n",
        "    with w_output:\n",
        "        clear_output()\n",
        "        ex = text2sql_data[idx]\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Difficulty: {ex['difficulty'].upper()}\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"\\n[Question]\\n{ex['instruction']}\\n\")\n",
        "        print(f\"[Schema Context]\\n{ex['context']}\\n\")\n",
        "        print(f\"[Gold SQL]\\n{ex['response']}\\n\")\n",
        "        ok, result = validate_sql(conn, ex['response'])\n",
        "        if ok:\n",
        "            df = pd.DataFrame(result)\n",
        "            print(f\"[Result Preview] ({len(result)} rows)\")\n",
        "            display(df.head(5))\n",
        "        else:\n",
        "            print(f\"[Execution Error] {result}\")\n",
        "\n",
        "widgets.interactive(show_example, idx=w_example_idx)\n",
        "display(w_example_idx, w_output)\n",
        "show_example(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise A: Add Your Own Templates\n",
        "\n",
        "Add **5 new templates** (mix of joins and aggregations) to `STUDENT_TEMPLATES`, then run the cell to regenerate and revalidate the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No student templates added yet. Add yours above!\n"
          ]
        }
      ],
      "source": [
        "# TODO: Add 5 new templates (instruction, sql, difficulty)\n",
        "STUDENT_TEMPLATES = [\n",
        "    # Example (uncomment and modify):\n",
        "    # (\"What is the minimum FICO score?\", \"SELECT MIN(fico_score) FROM customers;\", \"simple\"),\n",
        "]\n",
        "\n",
        "# Combine and rebuild\n",
        "if STUDENT_TEMPLATES:\n",
        "    combined = TEMPLATES + STUDENT_TEMPLATES\n",
        "    text2sql_data = build_dataset(conn, combined)\n",
        "    print(f\"Dataset rebuilt with student templates: {len(text2sql_data)} examples\")\n",
        "else:\n",
        "    print(\"No student templates added yet. Add yours above!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 3 — Baseline Inference (Before Tuning)\n",
        "\n",
        "We'll pick a small instruct model, define a prompt template, generate SQL for a few samples, then compute:\n",
        "- **Exact match** (normalized SQL)\n",
        "- **Execution match** (compare SQLite result sets)\n",
        "\n",
        "> Default model: `Qwen/Qwen2.5-1.5B-Instruct` (upgrade to 3B if you have VRAM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Helpers ready\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Prompt template + SQL normalization + execution-based eval\n",
        "# ============================================================\n",
        "\n",
        "def build_prompt(instruction: str, context: str) -> str:\n",
        "    return (\n",
        "        \"You are a Text-to-SQL assistant for an SQLite database.\\n\"\n",
        "        \"Return ONLY a single SQL query, no explanation.\\n\\n\"\n",
        "        f\"### Schema\\n{context}\\n\\n\"\n",
        "        f\"### Question\\n{instruction}\\n\\n\"\n",
        "        \"### SQL\\n\"\n",
        "    )\n",
        "\n",
        "_sql_ws = re.compile(r\"\\s+\")\n",
        "\n",
        "def normalize_sql(sql: str) -> str:\n",
        "    # Keep this intentionally simple: no heavyweight parsers.\n",
        "    s = sql.strip()\n",
        "    # Keep only the first statement (best-effort)\n",
        "    s = s.split(\";\")[0].strip()\n",
        "    s = s.replace(\"\\n\", \" \")\n",
        "    s = _sql_ws.sub(\" \", s)\n",
        "    s = s.strip().lower()\n",
        "    return s\n",
        "\n",
        "def safe_exec(conn: sqlite3.Connection, sql: str):\n",
        "    \"\"\"Return (ok, rows_or_error). Rows are returned as tuples.\"\"\"\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(sql)\n",
        "        rows = cur.fetchall()\n",
        "        return True, rows\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "def resultset_equal(a_rows, b_rows) -> bool:\n",
        "    \"\"\"Compare result sets ignoring row order (best-effort).\"\"\"\n",
        "    try:\n",
        "        a = sorted(list(a_rows))\n",
        "        b = sorted(list(b_rows))\n",
        "        return a == b\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def evaluate_predictions(conn, examples: List[Dict[str, Any]], preds: List[str]) -> pd.DataFrame:\n",
        "    records = []\n",
        "    for ex, pred in zip(examples, preds):\n",
        "        gold_sql = ex[\"response\"]\n",
        "        pred_sql = pred\n",
        "\n",
        "        gold_norm = normalize_sql(gold_sql)\n",
        "        pred_norm = normalize_sql(pred_sql)\n",
        "        exact = int(gold_norm == pred_norm)\n",
        "\n",
        "        ok_g, rows_g = safe_exec(conn, gold_sql)\n",
        "        ok_p, rows_p = safe_exec(conn, pred_sql)\n",
        "        exec_match = int(ok_g and ok_p and resultset_equal(rows_g, rows_p))\n",
        "\n",
        "        records.append({\n",
        "            \"difficulty\": ex[\"difficulty\"],\n",
        "            \"instruction\": ex[\"instruction\"],\n",
        "            \"gold_sql\": gold_sql,\n",
        "            \"pred_sql\": pred_sql,\n",
        "            \"exact_match\": exact,\n",
        "            \"exec_match\": exec_match,\n",
        "            \"pred_ok\": bool(ok_p),\n",
        "        })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "print(\"✅ Helpers ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Qwen/Qwen2.5-1.5B-Instruct\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Load base model (baseline)\n",
        "# ============================================================\n",
        "\n",
        "BASE_MODEL = \"Qwen/Qwen2.5-1.5B-Instruct\"  # try \"Qwen/Qwen2.5-3B-Instruct\" if VRAM allows\n",
        "\n",
        "# CPU-safe fallback (much smaller; for smoke tests only)\n",
        "CPU_FALLBACK_MODEL = \"sshleifer/tiny-gpt2\"\n",
        "\n",
        "use_model = BASE_MODEL\n",
        "\n",
        "# Heuristic: if no GPU, default to tiny fallback so the notebook is runnable.\n",
        "if DEVICE != \"cuda\":\n",
        "    print(\"⚠️ CPU mode detected: using a tiny fallback model for demonstration.\")\n",
        "    use_model = CPU_FALLBACK_MODEL\n",
        "\n",
        "print(\"Model:\", use_model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(use_model, use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Dtype/device_map\n",
        "dtype = torch.bfloat16 if (DEVICE == \"cuda\" and torch.cuda.is_bf16_supported()) else (torch.float16 if DEVICE == \"cuda\" else torch.float32)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    use_model,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=\"auto\" if DEVICE == \"cuda\" else None,\n",
        ")\n",
        "\n",
        "if DEVICE != \"cuda\":\n",
        "    model.to(\"cpu\")\n",
        "\n",
        "model.eval()\n",
        "print(\"✅ Model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 20 examples from held-out eval set\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>instruction</th>\n",
              "      <th>gold_sql</th>\n",
              "      <th>pred_sql</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>exec_match</th>\n",
              "      <th>pred_ok</th>\n",
              "      <th>tokens_per_sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>medium</td>\n",
              "      <td>Show the latest transaction date for each acco...</td>\n",
              "      <td>SELECT account_id, MAX(txn_date) FROM transact...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>64.735038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>complex</td>\n",
              "      <td>Show the monthly total transaction amount for ...</td>\n",
              "      <td>SELECT strftime('%Y-%m', txn_date) as month, S...</td>\n",
              "      <td>SELECT SUM(amount) AS total FROM transactions ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.347432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>medium</td>\n",
              "      <td>Show the number of distinct account types per ...</td>\n",
              "      <td>SELECT c.name, COUNT(DISTINCT a.account_type) ...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.466394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>complex</td>\n",
              "      <td>List account types that have an average balanc...</td>\n",
              "      <td>SELECT account_type FROM accounts GROUP BY acc...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.523266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>simple</td>\n",
              "      <td>How many customers have a FICO score above 800?</td>\n",
              "      <td>SELECT COUNT(*) FROM customers WHERE fico_scor...</td>\n",
              "      <td>SELECT COUNT(DISTINCT c.customer_id) FROM cust...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>65.720904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>medium</td>\n",
              "      <td>Show the total approved credit amount per cust...</td>\n",
              "      <td>SELECT c.name, SUM(ca.requested_amount) FROM c...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>64.180101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>simple</td>\n",
              "      <td>Show all customer names sorted alphabetically.</td>\n",
              "      <td>SELECT name FROM customers ORDER BY name ASC;</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>64.522349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>medium</td>\n",
              "      <td>List account IDs and the number of credit tran...</td>\n",
              "      <td>SELECT account_id, COUNT(*) FROM transactions ...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>64.486837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>simple</td>\n",
              "      <td>Retrieve the account ID for the account with t...</td>\n",
              "      <td>SELECT account_id FROM accounts ORDER BY balan...</td>\n",
              "      <td>SELECT account_id FROM accounts ORDER BY balan...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>66.641242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>complex</td>\n",
              "      <td>Find the maximum gap in days between transacti...</td>\n",
              "      <td>SELECT MAX(julianday(t1.txn_date) - julianday(...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.774118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>complex</td>\n",
              "      <td>Show the percentage of customers with email ad...</td>\n",
              "      <td>SELECT (CAST(SUM(CASE WHEN email LIKE '%@gmail...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>66.265258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>simple</td>\n",
              "      <td>List customers with 'Smith' in their name.</td>\n",
              "      <td>SELECT * FROM customers WHERE name LIKE '%Smit...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.875680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>simple</td>\n",
              "      <td>Show the balance of the account with the highe...</td>\n",
              "      <td>SELECT balance FROM accounts ORDER BY account_...</td>\n",
              "      <td>SELECT MAX(account_id) FROM accounts;</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>66.885117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>simple</td>\n",
              "      <td>List all accounts with a zero balance.</td>\n",
              "      <td>SELECT account_id FROM accounts WHERE balance ...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>66.501160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>complex</td>\n",
              "      <td>Show the account type that has the highest ave...</td>\n",
              "      <td>SELECT account_type FROM accounts GROUP BY acc...</td>\n",
              "      <td>SELECT account_type</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>66.195164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>simple</td>\n",
              "      <td>List the top 3 customers with the lowest FICO ...</td>\n",
              "      <td>SELECT name, fico_score FROM customers ORDER B...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>66.229412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>medium</td>\n",
              "      <td>Count how many transactions exist for each cus...</td>\n",
              "      <td>SELECT c.name, COUNT(t.txn_id) FROM customers ...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>66.263565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>medium</td>\n",
              "      <td>Count the number of denied applications per cu...</td>\n",
              "      <td>SELECT c.name, COUNT(ca.app_id) FROM customers...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>66.288650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>complex</td>\n",
              "      <td>Find the total balance of customers who have b...</td>\n",
              "      <td>SELECT SUM(a.balance) FROM customers c JOIN ac...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.470450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>simple</td>\n",
              "      <td>Count the number of customers with a 'prime' c...</td>\n",
              "      <td>SELECT COUNT(*) FROM customers WHERE fico_scor...</td>\n",
              "      <td>```sql</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>65.827781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   difficulty                                        instruction  \\\n",
              "0      medium  Show the latest transaction date for each acco...   \n",
              "1     complex  Show the monthly total transaction amount for ...   \n",
              "2      medium  Show the number of distinct account types per ...   \n",
              "3     complex  List account types that have an average balanc...   \n",
              "4      simple    How many customers have a FICO score above 800?   \n",
              "5      medium  Show the total approved credit amount per cust...   \n",
              "6      simple     Show all customer names sorted alphabetically.   \n",
              "7      medium  List account IDs and the number of credit tran...   \n",
              "8      simple  Retrieve the account ID for the account with t...   \n",
              "9     complex  Find the maximum gap in days between transacti...   \n",
              "10    complex  Show the percentage of customers with email ad...   \n",
              "11     simple         List customers with 'Smith' in their name.   \n",
              "12     simple  Show the balance of the account with the highe...   \n",
              "13     simple             List all accounts with a zero balance.   \n",
              "14    complex  Show the account type that has the highest ave...   \n",
              "15     simple  List the top 3 customers with the lowest FICO ...   \n",
              "16     medium  Count how many transactions exist for each cus...   \n",
              "17     medium  Count the number of denied applications per cu...   \n",
              "18    complex  Find the total balance of customers who have b...   \n",
              "19     simple  Count the number of customers with a 'prime' c...   \n",
              "\n",
              "                                             gold_sql  \\\n",
              "0   SELECT account_id, MAX(txn_date) FROM transact...   \n",
              "1   SELECT strftime('%Y-%m', txn_date) as month, S...   \n",
              "2   SELECT c.name, COUNT(DISTINCT a.account_type) ...   \n",
              "3   SELECT account_type FROM accounts GROUP BY acc...   \n",
              "4   SELECT COUNT(*) FROM customers WHERE fico_scor...   \n",
              "5   SELECT c.name, SUM(ca.requested_amount) FROM c...   \n",
              "6       SELECT name FROM customers ORDER BY name ASC;   \n",
              "7   SELECT account_id, COUNT(*) FROM transactions ...   \n",
              "8   SELECT account_id FROM accounts ORDER BY balan...   \n",
              "9   SELECT MAX(julianday(t1.txn_date) - julianday(...   \n",
              "10  SELECT (CAST(SUM(CASE WHEN email LIKE '%@gmail...   \n",
              "11  SELECT * FROM customers WHERE name LIKE '%Smit...   \n",
              "12  SELECT balance FROM accounts ORDER BY account_...   \n",
              "13  SELECT account_id FROM accounts WHERE balance ...   \n",
              "14  SELECT account_type FROM accounts GROUP BY acc...   \n",
              "15  SELECT name, fico_score FROM customers ORDER B...   \n",
              "16  SELECT c.name, COUNT(t.txn_id) FROM customers ...   \n",
              "17  SELECT c.name, COUNT(ca.app_id) FROM customers...   \n",
              "18  SELECT SUM(a.balance) FROM customers c JOIN ac...   \n",
              "19  SELECT COUNT(*) FROM customers WHERE fico_scor...   \n",
              "\n",
              "                                             pred_sql  exact_match  \\\n",
              "0                                              ```sql            0   \n",
              "1   SELECT SUM(amount) AS total FROM transactions ...            0   \n",
              "2                                              ```sql            0   \n",
              "3                                              ```sql            0   \n",
              "4   SELECT COUNT(DISTINCT c.customer_id) FROM cust...            0   \n",
              "5                                              ```sql            0   \n",
              "6                                              ```sql            0   \n",
              "7                                              ```sql            0   \n",
              "8   SELECT account_id FROM accounts ORDER BY balan...            0   \n",
              "9                                              ```sql            0   \n",
              "10                                             ```sql            0   \n",
              "11                                             ```sql            0   \n",
              "12              SELECT MAX(account_id) FROM accounts;            0   \n",
              "13                                             ```sql            0   \n",
              "14                                SELECT account_type            0   \n",
              "15                                             ```sql            0   \n",
              "16                                             ```sql            0   \n",
              "17                                             ```sql            0   \n",
              "18                                             ```sql            0   \n",
              "19                                             ```sql            0   \n",
              "\n",
              "    exec_match  pred_ok  tokens_per_sec  \n",
              "0            0    False       64.735038  \n",
              "1            0    False       65.347432  \n",
              "2            0    False       65.466394  \n",
              "3            0    False       65.523266  \n",
              "4            1     True       65.720904  \n",
              "5            0    False       64.180101  \n",
              "6            0    False       64.522349  \n",
              "7            0    False       64.486837  \n",
              "8            1     True       66.641242  \n",
              "9            0    False       65.774118  \n",
              "10           0    False       66.265258  \n",
              "11           0    False       65.875680  \n",
              "12           0     True       66.885117  \n",
              "13           0    False       66.501160  \n",
              "14           0    False       66.195164  \n",
              "15           0    False       66.229412  \n",
              "16           0    False       66.263565  \n",
              "17           0    False       66.288650  \n",
              "18           0    False       65.470450  \n",
              "19           0    False       65.827781  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Baseline generation on a handful of samples\n",
        "# ============================================================\n",
        "\n",
        "def generate_sql(model, tokenizer, instruction: str, context: str, max_new_tokens=128, temperature=0.0) -> str:\n",
        "    prompt = build_prompt(instruction, context)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    if DEVICE == \"cuda\":\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    else:\n",
        "        inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=(temperature > 0),\n",
        "        temperature=temperature if temperature > 0 else None,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**inputs, **{k: v for k, v in gen_kwargs.items() if v is not None})\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "    # Extract everything after the prompt\n",
        "    completion = text[len(prompt):].strip() if text.startswith(prompt) else text.strip()\n",
        "\n",
        "    # Best-effort: take first line/statement\n",
        "    completion = completion.split(\"\\n\")[0].strip()\n",
        "    if \";\" in completion:\n",
        "        completion = completion.split(\";\")[0].strip() + \";\"\n",
        "\n",
        "    # latency estimate\n",
        "    new_tokens = int(out.shape[-1] - inputs[\"input_ids\"].shape[-1])\n",
        "    tps = (new_tokens / dt) if dt > 0 and new_tokens > 0 else None\n",
        "    return completion, {\"seconds\": dt, \"new_tokens\": new_tokens, \"tokens_per_sec\": tps}\n",
        "\n",
        "# Use proper eval set if available, otherwise fallback to first N examples\n",
        "if 'text2sql_eval' in dir() and text2sql_eval:\n",
        "    EVAL_N = min(20, len(text2sql_eval))  # Use up to 20 eval examples\n",
        "    examples_eval = text2sql_eval[:EVAL_N]\n",
        "    print(f\"Using {EVAL_N} examples from held-out eval set\")\n",
        "else:\n",
        "    EVAL_N = 8\n",
        "    examples_eval = text2sql_data[:EVAL_N]\n",
        "    print(f\"Using first {EVAL_N} examples (no separate eval set)\")\n",
        "\n",
        "preds = []\n",
        "latencies = []\n",
        "for ex in examples_eval:\n",
        "    pred, lat = generate_sql(model, tokenizer, ex[\"instruction\"], ex[\"context\"], max_new_tokens=128)\n",
        "    preds.append(pred)\n",
        "    latencies.append(lat)\n",
        "\n",
        "baseline_df = evaluate_predictions(conn, examples_eval, preds)\n",
        "baseline_df[\"tokens_per_sec\"] = [x.get(\"tokens_per_sec\") for x in latencies]\n",
        "\n",
        "baseline_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline metrics (mean over sample):\n",
            "- exact_match: 0.000\n",
            "- exec_match: 0.100\n",
            "- pred_ok: 0.150\n",
            "- tokens_per_sec: 65.710\n"
          ]
        }
      ],
      "source": [
        "# Baseline metrics summary\n",
        "summary = baseline_df.agg({\n",
        "    \"exact_match\": \"mean\",\n",
        "    \"exec_match\": \"mean\",\n",
        "    \"pred_ok\": \"mean\",\n",
        "    \"tokens_per_sec\": \"mean\",\n",
        "}).to_dict()\n",
        "\n",
        "print(\"Baseline metrics (mean over sample):\")\n",
        "for k, v in summary.items():\n",
        "    if v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "        print(f\"- {k}: n/a\")\n",
        "    else:\n",
        "        print(f\"- {k}: {v:.3f}\" if isinstance(v, float) else f\"- {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4 — QLoRA Training (The Main Event)\n",
        "\n",
        "We’ll:\n",
        "1. Load the base model in **4-bit** (GPU recommended)\n",
        "2. Prepare it for k-bit training\n",
        "3. Attach LoRA adapters\n",
        "4. Train with `transformers.Trainer`\n",
        "5. Save adapters to: `workshop-v1/fico/artifacts/lora_text2sql/`\n",
        "\n",
        "> CPU is supported for the notebook’s *structure*, but QLoRA training is realistically **GPU-only** (bitsandbytes 4-bit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using stratified split: 198 train, 23 eval\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b31c65c8e034afeab0a8d9e82ab8af8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "023acb67a3304f32af3e7e134c3cdbd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train: Dataset({\n",
            "    features: ['instruction', 'context', 'response', 'difficulty', 'text'],\n",
            "    num_rows: 198\n",
            "})\n",
            "Eval:  Dataset({\n",
            "    features: ['instruction', 'context', 'response', 'difficulty', 'text'],\n",
            "    num_rows: 23\n",
            "})\n",
            "\n",
            "Example training text:\n",
            "\n",
            "You are a Text-to-SQL assistant for an SQLite database.\n",
            "Return ONLY a single SQL query, no explanation.\n",
            "\n",
            "### Schema\n",
            "Tables:\n",
            "- customers (customer_id, name, email, fico_score, created_at)\n",
            "- accounts (account_id, customer_id, account_type, balance, opened_at)\n",
            "- transactions (txn_id, account_id, amount, txn_type, txn_date)\n",
            "- credit_applications (app_id, customer_id, requested_amount, status, decision_date)\n",
            "\n",
            "### Question\n",
            "Select the latest 5 credit applications.\n",
            "\n",
            "### SQL\n",
            "SELECT * FROM credit_applications ORDER BY app_id DESC LIMIT 5;\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Build a training dataset in instruction format\n",
        "# ============================================================\n",
        "\n",
        "def format_example(ex: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    prompt = build_prompt(ex[\"instruction\"], ex[\"context\"])\n",
        "    # Supervised fine-tune text: prompt + gold SQL\n",
        "    text = prompt + ex[\"response\"].strip()\n",
        "    return {\"text\": text}\n",
        "\n",
        "# Use the stratified split if available (from external dataset cell above)\n",
        "# Otherwise fall back to the template-based text2sql_data\n",
        "if 'text2sql_train' in dir() and text2sql_train:\n",
        "    print(f\"Using stratified split: {len(text2sql_train)} train, {len(text2sql_eval)} eval\")\n",
        "    train_ds = Dataset.from_list(text2sql_train).map(format_example)\n",
        "    eval_ds = Dataset.from_list(text2sql_eval).map(format_example)\n",
        "else:\n",
        "    print(\"Using template-based dataset with random split\")\n",
        "    full_ds = Dataset.from_list(text2sql_data).map(format_example)\n",
        "    split = full_ds.train_test_split(test_size=0.25, seed=SEED)\n",
        "    train_ds = split[\"train\"]\n",
        "    eval_ds = split[\"test\"]\n",
        "\n",
        "print(f\"\\nTrain: {train_ds}\")\n",
        "print(f\"Eval:  {eval_ds}\")\n",
        "print(\"\\nExample training text:\\n\")\n",
        "print(train_ds[0][\"text\"][:600])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e08cee5b2bf4272a84adde5b10f3c0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3c8e84998854c10a75bba6a3f6c3eb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tokenized\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Tokenization\n",
        "# ============================================================\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    out = tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=False,\n",
        "    )\n",
        "    out[\"labels\"] = out[\"input_ids\"].copy()\n",
        "    return out\n",
        "\n",
        "train_tok = train_ds.map(tokenize_batch, batched=True, remove_columns=train_ds.column_names)\n",
        "eval_tok = eval_ds.map(tokenize_batch, batched=True, remove_columns=eval_ds.column_names)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "print(\"✅ Tokenized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adapter output dir: /home/shadeform/workshop-v1/fico/artifacts/lora_text2sql/adapter_20251215_214938\n",
            "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n",
            "✅ QLoRA model ready\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Load 4-bit model + attach LoRA adapters (GPU recommended)\n",
        "# ============================================================\n",
        "\n",
        "# Adapter save location\n",
        "ARTIFACT_ROOT = Path(\"/home/shadeform/workshop-v1/fico/artifacts/lora_text2sql\")\n",
        "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RUN_NAME = time.strftime(\"adapter_%Y%m%d_%H%M%S\")\n",
        "ADAPTER_DIR = ARTIFACT_ROOT / RUN_NAME\n",
        "\n",
        "print(\"Adapter output dir:\", ADAPTER_DIR)\n",
        "\n",
        "if DEVICE != \"cuda\":\n",
        "    print(\"\\n⚠️ Not on GPU. Skipping 4-bit QLoRA model load.\")\n",
        "    print(\"   You can still read the code; run on a GPU machine to train.\")\n",
        "\n",
        "# Default LoRA hyperparams (widgets below let you change these)\n",
        "LORA_R = 16\n",
        "LORA_ALPHA = 32\n",
        "LORA_DROPOUT = 0.05\n",
        "\n",
        "# Targets for Qwen-style architectures (common)\n",
        "DEFAULT_TARGET_MODULES = [\n",
        "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "    \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "]\n",
        "\n",
        "qlora_tokenizer = tokenizer\n",
        "qlora_model = None\n",
        "\n",
        "if DEVICE == \"cuda\":\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "    )\n",
        "\n",
        "    qlora_model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_MODEL,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    qlora_model = prepare_model_for_kbit_training(qlora_model)\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        r=LORA_R,\n",
        "        lora_alpha=LORA_ALPHA,\n",
        "        lora_dropout=LORA_DROPOUT,\n",
        "        target_modules=DEFAULT_TARGET_MODULES,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    qlora_model = get_peft_model(qlora_model, lora_cfg)\n",
        "    qlora_model.print_trainable_parameters()\n",
        "    print(\"✅ QLoRA model ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interactive: Tune LoRA Hyperparameters\n",
        "\n",
        "Adjust LoRA hyperparameters and training settings. This cell prints:\n",
        "- Trainable parameters\n",
        "- A rough adapter size estimate\n",
        "\n",
        "> For a real run: keep dataset small and training short (~10–20 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ebf9c34ef804b768874ffc7ad0db63b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(IntSlider(value=16, description='r', max=64, min=4, step=4), IntSlider(value=32,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Widgets for LoRA + training knobs\n",
        "w_r = widgets.IntSlider(value=16, min=4, max=64, step=4, description=\"r\")\n",
        "w_alpha = widgets.IntSlider(value=32, min=8, max=256, step=8, description=\"alpha\")\n",
        "w_dropout = widgets.FloatSlider(value=0.05, min=0.0, max=0.3, step=0.01, description=\"dropout\")\n",
        "\n",
        "w_epochs = widgets.IntSlider(value=1, min=1, max=5, step=1, description=\"epochs\")\n",
        "w_train_bs = widgets.IntSlider(value=1, min=1, max=8, step=1, description=\"batch\")\n",
        "w_grad_accum = widgets.IntSlider(value=8, min=1, max=32, step=1, description=\"grad_acc\")\n",
        "\n",
        "w_max_steps = widgets.IntSlider(value=120, min=20, max=1000, step=20, description=\"max_steps\")\n",
        "w_ds_limit = widgets.IntSlider(value=min(64, len(train_tok)), min=16, max=max(16, len(train_tok)), step=16, description=\"train_n\")\n",
        "\n",
        "w_info = widgets.Output()\n",
        "\n",
        "def _estimate_adapter_mb(trainable_params: int, dtype_bytes: int = 2) -> float:\n",
        "    return (trainable_params * dtype_bytes) / 1e6\n",
        "\n",
        "def refresh_info(*_):\n",
        "    with w_info:\n",
        "        clear_output()\n",
        "        print(\"Training config preview\")\n",
        "        print(\"- r:\", w_r.value)\n",
        "        print(\"- alpha:\", w_alpha.value)\n",
        "        print(\"- dropout:\", w_dropout.value)\n",
        "        print(\"- epochs:\", w_epochs.value)\n",
        "        print(\"- per_device_train_batch_size:\", w_train_bs.value)\n",
        "        print(\"- gradient_accumulation_steps:\", w_grad_accum.value)\n",
        "        print(\"- max_steps:\", w_max_steps.value)\n",
        "        print(\"- train subset size:\", w_ds_limit.value)\n",
        "\n",
        "        if DEVICE != \"cuda\":\n",
        "            print(\"\\n⚠️ GPU not detected: QLoRA training cells are for reference.\")\n",
        "            return\n",
        "\n",
        "        if qlora_model is None:\n",
        "            print(\"\\nℹ️ QLoRA model object exists only after you run the QLoRA load cell above.\")\n",
        "            return\n",
        "\n",
        "        trainable = sum(p.numel() for p in qlora_model.parameters() if p.requires_grad)\n",
        "        print(\"\\nTrainable params:\", f\"{trainable:,}\")\n",
        "        print(\"Approx adapter size (fp16/bf16):\", f\"{_estimate_adapter_mb(trainable):.2f} MB\")\n",
        "\n",
        "for w in [w_r, w_alpha, w_dropout, w_epochs, w_train_bs, w_grad_accum, w_max_steps, w_ds_limit]:\n",
        "    w.observe(refresh_info, names=\"value\")\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HBox([w_r, w_alpha, w_dropout]),\n",
        "    widgets.HBox([w_epochs, w_train_bs, w_grad_accum]),\n",
        "    widgets.HBox([w_max_steps, w_ds_limit]),\n",
        "    w_info,\n",
        "]))\n",
        "refresh_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training adapter to: /home/shadeform/workshop-v1/fico/artifacts/lora_text2sql/adapter_20251215_214938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 18,464,768 || all params: 1,562,179,072 || trainable%: 1.1820\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 04:41, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.083600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.101100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.056700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.043700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.031500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainOutput(global_step=120, training_loss=0.1562273661295573, metrics={'train_runtime': 284.3729, 'train_samples_per_second': 3.376, 'train_steps_per_second': 0.422, 'total_flos': 1124647718031360.0, 'train_loss': 0.1562273661295573, 'epoch': 15.0})\n",
            "Train wall time: 4.7 min\n",
            "\n",
            "Saved files:\n",
            "- README.md\n",
            "- adapter_config.json\n",
            "- adapter_model.safetensors\n",
            "- added_tokens.json\n",
            "- chat_template.jinja\n",
            "- merges.txt\n",
            "- special_tokens_map.json\n",
            "- tokenizer.json\n",
            "- tokenizer_config.json\n",
            "- trainer_out\n",
            "- vocab.json\n",
            "\n",
            "✅ Saved adapter to /home/shadeform/workshop-v1/fico/artifacts/lora_text2sql/adapter_20251215_214938\n",
            "✅ Adapter is loadable (adapter_config.json present)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Train (QLoRA)\n",
        "# ============================================================\n",
        "\n",
        "if DEVICE != \"cuda\":\n",
        "    print(\"⚠️ Skipping training (no GPU).\")\n",
        "else:\n",
        "    print(\"Training adapter to:\", ADAPTER_DIR)\n",
        "\n",
        "    # Re-load the quantized base model to apply the current widget settings.\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "    )\n",
        "\n",
        "    qlora_model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_MODEL,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    qlora_model.gradient_checkpointing_enable()\n",
        "    qlora_model = prepare_model_for_kbit_training(qlora_model)\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        r=w_r.value,\n",
        "        lora_alpha=w_alpha.value,\n",
        "        lora_dropout=w_dropout.value,\n",
        "        target_modules=DEFAULT_TARGET_MODULES,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    qlora_model = get_peft_model(qlora_model, lora_cfg)\n",
        "    qlora_model.print_trainable_parameters()\n",
        "\n",
        "    # Subset training set for speed\n",
        "    train_subset = train_tok.select(range(min(w_ds_limit.value, len(train_tok))))\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=str(ADAPTER_DIR / \"trainer_out\"),\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=w_epochs.value,\n",
        "        max_steps=w_max_steps.value,\n",
        "        per_device_train_batch_size=w_train_bs.value,\n",
        "        gradient_accumulation_steps=w_grad_accum.value,\n",
        "        learning_rate=2e-4,\n",
        "        warmup_ratio=0.03,\n",
        "        logging_steps=10,\n",
        "        save_strategy=\"no\",\n",
        "        eval_strategy=\"no\",\n",
        "        fp16=(not torch.cuda.is_bf16_supported()),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        report_to=[],\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=qlora_model,\n",
        "        args=args,\n",
        "        train_dataset=train_subset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    t0 = time.time()\n",
        "    train_result = trainer.train()\n",
        "    dt = time.time() - t0\n",
        "    print(train_result)\n",
        "    print(f\"Train wall time: {dt/60:.1f} min\")\n",
        "\n",
        "    # Save adapter + tokenizer\n",
        "    ADAPTER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    qlora_model.save_pretrained(str(ADAPTER_DIR))\n",
        "    tokenizer.save_pretrained(str(ADAPTER_DIR))\n",
        "\n",
        "    # Verify artifacts\n",
        "    print(\"\\nSaved files:\")\n",
        "    for p in sorted(ADAPTER_DIR.glob(\"*\")):\n",
        "        print(\"-\", p.name)\n",
        "\n",
        "    cfg = ADAPTER_DIR / \"adapter_config.json\"\n",
        "    if not cfg.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Training finished but adapter_config.json was not found in {ADAPTER_DIR}. \"\n",
        "            \"This usually means save_pretrained did not run or failed.\"\n",
        "        )\n",
        "\n",
        "    print(\"\\n✅ Saved adapter to\", ADAPTER_DIR)\n",
        "    print(\"✅ Adapter is loadable (adapter_config.json present)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on 20 held-out examples\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Load base + adapter for inference (post-tune) and evaluate\n",
        "# ============================================================\n",
        "\n",
        "post_df = None\n",
        "\n",
        "\n",
        "def _find_latest_adapter_dir(root: Path) -> Path | None:\n",
        "    if not root.exists():\n",
        "        return None\n",
        "    candidates = []\n",
        "    for p in root.glob(\"adapter_*/\"):\n",
        "        cfg = p / \"adapter_config.json\"\n",
        "        if cfg.exists():\n",
        "            candidates.append(p)\n",
        "    if not candidates:\n",
        "        return None\n",
        "    return sorted(candidates, key=lambda x: x.name)[-1]\n",
        "\n",
        "\n",
        "if DEVICE != \"cuda\":\n",
        "    print(\"⚠️ No GPU: skipping adapter eval (you can still run baseline eval above).\")\n",
        "else:\n",
        "    # Resolve adapter dir robustly (only proceed if adapter_config.json exists)\n",
        "    artifact_root = Path(\"/home/shadeform/workshop-v1/fico/artifacts/lora_text2sql\")\n",
        "    adapter_dir = Path(str(ADAPTER_DIR))\n",
        "\n",
        "    if not (adapter_dir / \"adapter_config.json\").exists():\n",
        "        latest = _find_latest_adapter_dir(artifact_root)\n",
        "        if latest is None:\n",
        "            print(\"⚠️ No saved adapter found yet.\")\n",
        "            print(\"   Run the 'Train (QLoRA)' cell first (it should print '✅ Saved adapter to ...'),\")\n",
        "            print(\"   then re-run this evaluation cell.\")\n",
        "            print(f\"   Expected: {adapter_dir}/adapter_config.json\")\n",
        "            print(f\"   Searched: {artifact_root}/adapter_*/adapter_config.json\")\n",
        "        else:\n",
        "            print(f\"⚠️ ADAPTER_DIR has no adapter_config.json. Using latest adapter: {latest}\")\n",
        "            adapter_dir = latest\n",
        "\n",
        "    if (adapter_dir / \"adapter_config.json\").exists():\n",
        "        # Load base model in 4-bit again\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "        )\n",
        "\n",
        "        base4 = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "\n",
        "        tuned = PeftModel.from_pretrained(base4, str(adapter_dir), is_trainable=False)\n",
        "        tuned.eval()\n",
        "\n",
        "        # Use the same eval set as baseline for fair comparison\n",
        "        if 'text2sql_eval' in dir() and text2sql_eval:\n",
        "            EVAL_N = min(20, len(text2sql_eval))\n",
        "            examples_eval = text2sql_eval[:EVAL_N]\n",
        "            print(f\"Evaluating on {EVAL_N} held-out examples\")\n",
        "        else:\n",
        "            EVAL_N = 8\n",
        "            examples_eval = text2sql_data[:EVAL_N]\n",
        "        \n",
        "        preds = []\n",
        "        lats = []\n",
        "        for ex in examples_eval:\n",
        "            pred, lat = generate_sql(tuned, tokenizer, ex[\"instruction\"], ex[\"context\"], max_new_tokens=128)\n",
        "            preds.append(pred)\n",
        "            lats.append(lat)\n",
        "\n",
        "        post_df = evaluate_predictions(conn, examples_eval, preds)\n",
        "        post_df[\"tokens_per_sec\"] = [x.get(\"tokens_per_sec\") for x in lats]\n",
        "        post_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📊 Comparison: Baseline vs Fine-Tuned\n",
        "\n",
        "Run this cell after both the baseline evaluation (Part 3) and post-tune evaluation above to see a side-by-side comparison of performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "📊 COMPARISON: Baseline vs Fine-Tuned Model\n",
            "============================================================\n",
            "\n",
            "Samples evaluated: Baseline=20, Fine-Tuned=20\n",
            "\n",
            "     Metric  Baseline (Before)  Fine-Tuned (After)  Improvement  Improvement (%)\n",
            "exact_match               0.0%               40.0%        40.0%          4000.0%\n",
            " exec_match              10.0%               60.0%        50.0%           500.0%\n",
            "\n",
            "⚡ Throughput: Baseline=65.7 tok/s, Fine-Tuned=17.6 tok/s\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "marker": {
                    "color": "lightcoral"
                  },
                  "name": "Baseline",
                  "text": [
                    "0.0%",
                    "10.0%"
                  ],
                  "textposition": "outside",
                  "type": "bar",
                  "x": [
                    "exact_match",
                    "exec_match"
                  ],
                  "xaxis": "x",
                  "y": [
                    0,
                    10
                  ],
                  "yaxis": "y"
                },
                {
                  "marker": {
                    "color": "mediumseagreen"
                  },
                  "name": "Fine-Tuned",
                  "text": [
                    "40.0%",
                    "60.0%"
                  ],
                  "textposition": "outside",
                  "type": "bar",
                  "x": [
                    "exact_match",
                    "exec_match"
                  ],
                  "xaxis": "x",
                  "y": [
                    40,
                    60
                  ],
                  "yaxis": "y"
                },
                {
                  "hovertemplate": "Baseline: %{x}<br>Fine-Tuned: %{y}<extra></extra>",
                  "marker": {
                    "color": "steelblue",
                    "opacity": 0.6,
                    "size": 10
                  },
                  "mode": "markers",
                  "name": "Samples",
                  "type": "scatter",
                  "x": {
                    "bdata": "+CDWI1Dohj8Ci7PfOXWiv+BlvKbNSJW/gIIK+nxei79lejw1A9zvP/yGHXu3M50/CiaBId/Anr/AA8QvW1JXP45/sV7aJfA/Qnnl4MM4p7+odmqRcgaGP4WAt5aB3qC/FBG3rPREpr92Gm7sofumP2YXztYh16c/mLu7kXOUnz9Xe5jM7gGUvx20hV5kmaS/ODF86Y7dkj+AumpDd4N4vw==",
                    "dtype": "f8"
                  },
                  "xaxis": "x2",
                  "y": {
                    "bdata": "QqxHoNAt8D8Ci7PfOXWiv9EcypK5Ve8/gIIK+nxei79lejw1A9zvPxx27N3OdPA/0PbzBvkJ7z/AA8QvW1JXP45/sV7aJfA/Qnnl4MM4p7/t1CLlDCzwP4WAt5aB3qC/FBG3rPREpr/UcGMP3bfwP7twtg65vvA/mLu7kXOUnz8lPJuJ8F/vP76kF7pptu4/ODF86Y7dkj+LKnkR+c7vPw==",
                    "dtype": "f8"
                  },
                  "yaxis": "y2"
                },
                {
                  "line": {
                    "color": "gray",
                    "dash": "dash"
                  },
                  "mode": "lines",
                  "name": "No Change",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [
                    0,
                    1
                  ],
                  "xaxis": "x2",
                  "y": [
                    0,
                    1
                  ],
                  "yaxis": "y2"
                }
              ],
              "layout": {
                "annotations": [
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Accuracy Metrics (%)",
                    "x": 0.225,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  },
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Per-Sample Comparison",
                    "x": 0.775,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  }
                ],
                "barmode": "group",
                "height": 450,
                "showlegend": true,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "🔬 Model Comparison: Before vs After Fine-Tuning"
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    0.45
                  ]
                },
                "xaxis2": {
                  "anchor": "y2",
                  "domain": [
                    0.55,
                    1
                  ],
                  "range": [
                    -0.1,
                    1.1
                  ],
                  "title": {
                    "text": "Baseline exec_match"
                  }
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "range": [
                    0,
                    110
                  ]
                },
                "yaxis2": {
                  "anchor": "x2",
                  "domain": [
                    0,
                    1
                  ],
                  "range": [
                    -0.1,
                    1.1
                  ],
                  "title": {
                    "text": "Fine-Tuned exec_match"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Queries FIXED by fine-tuning: 10\n",
            "❌ Queries REGRESSED by fine-tuning: 0\n",
            "\n",
            "--- Example of FIXED query ---\n",
            "Question: Show the latest transaction date for each account.\n",
            "Baseline pred: ```sql\n",
            "Fine-tuned pred: SELECT account_id, MAX(txn_date) FROM transactions GROUP BY account_id;\n",
            "Gold SQL: SELECT account_id, MAX(txn_date) FROM transactions GROUP BY account_id;\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Compare Baseline vs Fine-Tuned Model\n",
        "# ============================================================\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Check that both dataframes exist\n",
        "if 'baseline_df' not in dir() or baseline_df is None:\n",
        "    print(\"⚠️ Run the baseline evaluation cell first (Part 3).\")\n",
        "elif 'post_df' not in dir() or post_df is None:\n",
        "    print(\"⚠️ Run the post-tune evaluation cell first (after training).\")\n",
        "else:\n",
        "    # Compute summary metrics for both\n",
        "    metrics = [\"exact_match\", \"exec_match\", \"result_match\"]\n",
        "    \n",
        "    baseline_means = {m: baseline_df[m].mean() for m in metrics if m in baseline_df.columns}\n",
        "    posttune_means = {m: post_df[m].mean() for m in metrics if m in post_df.columns}\n",
        "    \n",
        "    # Create comparison dataframe\n",
        "    comparison = pd.DataFrame({\n",
        "        \"Metric\": list(baseline_means.keys()),\n",
        "        \"Baseline (Before)\": [baseline_means[m] * 100 for m in baseline_means.keys()],\n",
        "        \"Fine-Tuned (After)\": [posttune_means.get(m, 0) * 100 for m in baseline_means.keys()],\n",
        "    })\n",
        "    comparison[\"Improvement\"] = comparison[\"Fine-Tuned (After)\"] - comparison[\"Baseline (Before)\"]\n",
        "    comparison[\"Improvement (%)\"] = (comparison[\"Improvement\"] / comparison[\"Baseline (Before)\"].replace(0, 1)) * 100\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"📊 COMPARISON: Baseline vs Fine-Tuned Model\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nSamples evaluated: Baseline={len(baseline_df)}, Fine-Tuned={len(post_df)}\")\n",
        "    print(\"\\n\" + comparison.to_string(index=False, float_format=lambda x: f\"{x:.1f}%\"))\n",
        "    \n",
        "    # Latency comparison if available\n",
        "    if \"tokens_per_sec\" in baseline_df.columns and \"tokens_per_sec\" in post_df.columns:\n",
        "        base_tps = baseline_df[\"tokens_per_sec\"].mean()\n",
        "        post_tps = post_df[\"tokens_per_sec\"].mean()\n",
        "        print(f\"\\n⚡ Throughput: Baseline={base_tps:.1f} tok/s, Fine-Tuned={post_tps:.1f} tok/s\")\n",
        "    \n",
        "    # Create visualization\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        subplot_titles=(\"Accuracy Metrics (%)\", \"Per-Sample Comparison\"),\n",
        "        specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
        "    )\n",
        "    \n",
        "    # Bar chart comparing metrics\n",
        "    x_labels = comparison[\"Metric\"].tolist()\n",
        "    fig.add_trace(\n",
        "        go.Bar(name=\"Baseline\", x=x_labels, y=comparison[\"Baseline (Before)\"].tolist(), \n",
        "               marker_color=\"lightcoral\", text=[f\"{v:.1f}%\" for v in comparison[\"Baseline (Before)\"]], textposition=\"outside\"),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Bar(name=\"Fine-Tuned\", x=x_labels, y=comparison[\"Fine-Tuned (After)\"].tolist(), \n",
        "               marker_color=\"mediumseagreen\", text=[f\"{v:.1f}%\" for v in comparison[\"Fine-Tuned (After)\"]], textposition=\"outside\"),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Scatter plot: per-sample exec_match comparison (if same samples)\n",
        "    if len(baseline_df) == len(post_df) and \"exec_match\" in baseline_df.columns:\n",
        "        # Jitter for visibility\n",
        "        import numpy as np\n",
        "        jitter = np.random.uniform(-0.05, 0.05, len(baseline_df))\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=baseline_df[\"exec_match\"] + jitter, \n",
        "                y=post_df[\"exec_match\"] + jitter,\n",
        "                mode=\"markers\",\n",
        "                marker=dict(size=10, opacity=0.6, color=\"steelblue\"),\n",
        "                name=\"Samples\",\n",
        "                hovertemplate=\"Baseline: %{x}<br>Fine-Tuned: %{y}<extra></extra>\"\n",
        "            ),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        # Diagonal line (no improvement)\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", line=dict(dash=\"dash\", color=\"gray\"), \n",
        "                       name=\"No Change\", showlegend=False),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        fig.update_xaxes(title_text=\"Baseline exec_match\", range=[-0.1, 1.1], row=1, col=2)\n",
        "        fig.update_yaxes(title_text=\"Fine-Tuned exec_match\", range=[-0.1, 1.1], row=1, col=2)\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=\"🔬 Model Comparison: Before vs After Fine-Tuning\",\n",
        "        barmode=\"group\",\n",
        "        height=450,\n",
        "        showlegend=True\n",
        "    )\n",
        "    fig.update_yaxes(range=[0, 110], row=1, col=1)\n",
        "    fig.show()\n",
        "    \n",
        "    # Show examples where fine-tuning helped\n",
        "    if \"exec_match\" in baseline_df.columns and \"exec_match\" in post_df.columns:\n",
        "        improved = (post_df[\"exec_match\"] == 1) & (baseline_df[\"exec_match\"] == 0)\n",
        "        regressed = (post_df[\"exec_match\"] == 0) & (baseline_df[\"exec_match\"] == 1)\n",
        "        \n",
        "        print(f\"\\n✅ Queries FIXED by fine-tuning: {improved.sum()}\")\n",
        "        print(f\"❌ Queries REGRESSED by fine-tuning: {regressed.sum()}\")\n",
        "        \n",
        "        if improved.sum() > 0:\n",
        "            print(\"\\n--- Example of FIXED query ---\")\n",
        "            idx = improved.idxmax()\n",
        "            print(f\"Question: {baseline_df.loc[idx, 'instruction']}\")\n",
        "            print(f\"Baseline pred: {baseline_df.loc[idx, 'pred_sql']}\")\n",
        "            print(f\"Fine-tuned pred: {post_df.loc[idx, 'pred_sql']}\")\n",
        "            print(f\"Gold SQL: {baseline_df.loc[idx, 'gold_sql']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Select the latest 5 credit applications.\n",
            "Gold SQL: SELECT * FROM credit_applications ORDER BY app_id DESC LIMIT 5;\n",
            "Pred SQL: SELECT * FROM credit_applications ORDER BY app_id DESC LIMIT 5;\n",
            "Latency: {'seconds': 7.46020770072937, 'new_tokens': 128, 'tokens_per_sec': 17.157699240395907}\n"
          ]
        }
      ],
      "source": [
        "# Load base + adapter for inference (deployment pattern)\n",
        "if DEVICE != \"cuda\":\n",
        "    print(\"CPU mode: shown for reference\")\n",
        "else:\n",
        "    artifact_root = Path(\"/home/shadeform/workshop-v1/fico/artifacts/lora_text2sql\")\n",
        "    adapter_dir = Path(str(ADAPTER_DIR))\n",
        "    if not (adapter_dir / \"adapter_config.json\").exists():\n",
        "        adapter_dir = _find_latest_adapter_dir(artifact_root) or adapter_dir\n",
        "\n",
        "    if not (adapter_dir / \"adapter_config.json\").exists():\n",
        "        print(\"⚠️ No saved adapter found. Run the 'Train (QLoRA)' cell first.\")\n",
        "    else:\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "        )\n",
        "\n",
        "        base4 = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "\n",
        "        deployed = PeftModel.from_pretrained(base4, str(adapter_dir), is_trainable=False)\n",
        "        deployed.eval()\n",
        "\n",
        "        # Quick demo\n",
        "        ex = text2sql_data[0]\n",
        "        pred, lat = generate_sql(deployed, tokenizer, ex[\"instruction\"], ex[\"context\"], max_new_tokens=128)\n",
        "        print(\"Question:\", ex[\"instruction\"])\n",
        "        print(\"Gold SQL:\", ex[\"response\"])\n",
        "        print(\"Pred SQL:\", pred)\n",
        "        print(\"Latency:\", lat)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
