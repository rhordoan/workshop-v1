numpy>=1.24
pandas>=2.0
plotly>=5.22
ipywidgets>=8.0
ipykernel>=6.0
scikit-learn>=1.3
nbformat>=5.10
jupyterlab>=4.0

# Notebook visuals + GPU introspection (Inference Cockpit)
matplotlib>=3.7
# Provides the `pynvml` import (NVML bindings) via the maintained package name.
nvidia-ml-py>=12.0.0

# Day 2 vector arithmetic demos (king - man + woman)
gensim>=4.3.2
scipy>=1.10

# ---- GPU text generation + embeddings (optional but recommended) ----
# NOTE: For A100/CUDA, install the CUDA-enabled PyTorch wheel that matches your system.
# See: https://pytorch.org/get-started/locally/
torch>=2.1
transformers>=4.44
accelerate>=0.33
peft>=0.12
sentence-transformers>=3.0
tqdm>=4.66
jinja2>=3.1.0

# vLLM is optional and environment-sensitive (CUDA wheels, driver/toolkit matching).
# Install separately if desired:
#   python -m pip install -U vllm

# Module C: real RAG pipeline + NIM calls + eval
requests>=2.31
faiss-cpu>=1.8
ragas>=0.1.16
datasets>=2.20
langchain>=0.2
langchain-community>=0.2
langchain-openai>=0.2

# Day 3 Observability: OpenTelemetry tracing (OTLP -> collector -> Jaeger)
opentelemetry-api>=1.26
opentelemetry-sdk>=1.26
opentelemetry-exporter-otlp-proto-http>=1.26
opentelemetry-instrumentation>=0.47b0
opentelemetry-instrumentation-requests>=0.47b0
opentelemetry-semantic-conventions>=0.47b0


# Module D: Guardrails Arena
nemoguardrails>=0.10
websockets>=12.0
uvicorn>=0.30

# Module E: Quantization Lab
bitsandbytes>=0.43
auto-gptq>=0.7
optimum>=1.17
